#'
#' @return a (4k, 1) vector of beta coefficients
#'
#' @examples
#' #assuming you've run >sim <- simulate_ABk(...)
#' design_1 <- design_matrix_ABk(sim$df[sim$df$case == 1, "treatment"], k = 2)
#' y_1 <- sim$df[sim$df$case == 1, "outcome"]
#' sigma_1 <- AR1_matrix(phi = 0.4, rho = 0.05, times = 1:14)
#' beta_vec <- beta_vector(design_1, y_1, sigma_1)
#' #NOTE: beta_vec is [intercept_1, intercept_2,...,intercept_k, slope_1, slope_2,...,slope_k], and should match corresp values in sim$betas
beta_vector <- function(X, y, Sigma){
precision <- solve(Sigma)
return(solve(t(X)%*%precision%*%X)%*%t(X)%*%precision%*%y) #this beta vector might be ordered improperly, should be [intercept_1, slope_1, ...]
}
##----------------------------------------------------------------------------------------------------------------
## Obtain variance about regression line for case i
##----------------------------------------------------------------------------------------------------------------
#' @title var_i
#'
#' @description calculate the variance about the regression line for case i
#'
#' @param X the (4k, N_i)-dimensional design matrix for case i.
#' @param y the vector of N_i outcomes for case i
#' @param Sigma the AR(1) covariance matrix
#' @param k number of complete sub-phase cycles, as in (AB)^k
#'
#' @export
#'
#' @return sigma_sq_i estimate, A_i an (N_i, N_i)-dimensional matrix (latter value necessary for combining treatment effects across individuals)
#'
#' @examples
#' #assuming you've run >sim <- simulate_ABk(...)
#' sigma_calcs <- var_i(design_1, y_1, sigma_1, k = 2)
var_i <- function(X, y, Sigma, k){
N_i <- length(y)
precision <- solve(Sigma)
#probably precision%*%X (N_i x 4k) AND NOT
#precision%*%t(X) (non-conformable)
A_i <- (1/(N_i-4*k))*(diag(1, N_i) - precision%*%X%*%solve((t(X)%*%precision%*%X))%*%t(X)%*%precision)
sigma_sq_i <- t(y)%*%A_i%*%y
return(list(sigma_sq_i = sigma_sq_i, A_i = A_i))
}
##----------------------------------------------------------------------------------------------------------------
## Obtain average treatment effect of case i
##----------------------------------------------------------------------------------------------------------------
#' @title T_bar_individual
#'
#' @description calculate the mean treatment effect for an individual case
#'
#' @param beta the (4k, 1) vector of coefficients ordered [intercept1, intercept2,...,interceptk, slope1, slope2,...,slopek]
#' @param c_i the (4k, 1) vector of multipliers and midpoints for counting up beta coefficients
#' @param k number of complete sub-phase cycles, as in (AB)^k
#'
#' @export
#'
#' @return the average T estimate for one case
T_bar_individual <- function(beta, c_i, k){
t(c_i)%*%beta/(2*k - 1) #note, paper could be missing 2*k - 1 denominator factor
}
##################################################################################################################
############################################## TEST IMPLEMENTATION ###############################################
##################################################################################################################
phi <- 0.4; k <- 2; rho = 0.5
sim_df <- simulate_ABk_no_outcome(m = 6, n = 20, k = k) #all cases have identical baseline/treatment time profiles
trt_vec_1 <- sim_df[sim_df$case == 1, "treatment"] #representative of all time profiles
c_vec <- c_vector(trt_vec_1, k = k, x_is = gather_midpoints(trt_vec_1, k = k))
beta_data <- beta_given_delta(3.0, c_vec, sigma = 1, tau = 1, slope_baseline = 0.5, slope_treatment = 3)
beta <- beta_data$beta
sim_data <- simulate_ABk_outcomes(sim_df, beta, 2, phi = phi, sigma = 1, tau = 1)
case <- sim_data$df[sim_data$df$case == 1, ]
y_1 <- as.matrix(case$outcome)
trt_vec <- case$treatment
X_1 <- design_matrix_ABk(trt_vec_1, k)
time_vec <- case$time
beta_est <- beta_vector(X_1, y_1, sigma_1)
print("Estimated linear coefficients:")
print(t(beta_vec)) #coefficients are out of order...
print("Actual linear coefficients:")
print(betas[1, ])
intercepts <- beta_vec[1:(2*k)]; slopes <- beta_vec[((2*k)+1):(4*k)]
beta_vec_reorder <- vector(mode = "numeric", length = 4*k)
for(i in seq(1, 2*k)){
beta_vec_reorder[(2*i)-1] <- intercepts[i]
beta_vec_reorder[2*i] <- slopes[i]
}
sigma1 <- AR1_matrix(phi, rho, times)
beta_est <- beta_vector(X_1, y_1, sigma_1)
sigma_1 <- AR1_matrix(phi, rho, times)
beta_est <- beta_vector(X_1, y_1, sigma_1)
sigma_1
sigma_1 <- AR1_matrix(phi, rho, time_vec)
beta_est <- beta_vector(X_1, y_1, sigma_1)
beta_est
beta
intercepts <- beta_vec[1:(2*k)]; slopes <- beta_vec[((2*k)+1):(4*k)]
beta_vec_reorder <- vector(mode = "numeric", length = 4*k)
for(i in seq(1, 2*k)){
beta_vec_reorder[(2*i)-1] <- intercepts[i]
beta_vec_reorder[2*i] <- slopes[i]
}
print("Re-ordered linear coefficients:")
print(beta_vec_reorder)
beta_est
print("Estimated linear coefficients:")
print(t(beta_est)) #coefficients are out of order...
print("Actual linear coefficients:")
print(beta[1, ])
beta
print("Estimated linear coefficients:")
print(t(beta_est)) #coefficients are out of order...
print("Actual linear coefficients:")
print(t(beta))
intercepts <- beta_est[1:(2*k)]; slopes <- beta_est[((2*k)+1):(4*k)]
beta_est_reorder <- vector(mode = "numeric", length = 4*k)
for(i in seq(1, 2*k)){
beta_est_reorder[(2*i)-1] <- intercepts[i]
beta_est_reorder[2*i] <- slopes[i]
}
print("Re-ordered linear coefficients:")
print(beta_est_reorder)
print("Estimated linear coefficients:")
print(t(beta_est)) #coefficients are out of order...
print("Actual linear coefficients:")
print(t(beta))
print("Re-ordered linear coefficients:")
print(beta_est_reorder)
xgb_grid_1 = expand.grid(
nrounds = 1000,
eta = c(0.01, 0.001, 0.0001),
max_depth = c(2, 4, 6, 8, 10),
gamma = 1
)
xgb_grid_1
library(xgboost)
?predict()
?xgboost:predict()
?xgboost::predict()
man()
?help()
help(xgboost::predict)
help(xgboost::predict())
library(pROC)
?auc
install.packages("ROCR")
library(rocr)
library(ROCR)
?peformance
?performance
library(ggplot2)
auc_data <- data.frame("fpr" = unlist(perf@x.values), "tpr" = unlist(perf@y.values))
auc_data <- data.frame("fpr" = unlist(rocr_perf@x.values), "tpr" = unlist(rocr_perf@y.values))
ocr_perf <- performance(rocr_pred, measure = "tpr", x.measure = "fpr") #this is of class "performance," it's not a list
auc_data <- data.frame("fpr" = unlist(rocr_perf@x.values), "tpr" = unlist(rocr_perf@y.values))
rocr_pred <- prediction(valid.preds$good, y[-trainIndex])
rocr_perf <- performance(rocr_pred, measure = "tpr", x.measure = "fpr") #this is of class "performance," it's not a list
auc_data <- data.frame("fpr" = unlist(rocr_perf@x.values), "tpr" = unlist(rocr_perf@y.values))
sgn(-5)
sign(-5)
04
runif(3)
hist(runif(1000))
mean(runif(1000))
mean(runif(100000))
mean(runif(10000000))
mean(runif(10000000, min = 0, max = 2))
mtcars
scale(mtcars)
pca.1 <- pca(mtcars)
pca.1 <- PCA(mtcars)
?PCA
pca.1 <- prcomp(mtcars, center = T, scale. = T)
pca.1$rotation
pca.1$center
a <- list(one = 1, two = 2, three = 3)
a
as.vector(a)
as.matrix(a)
b <- list(one = 1.2, two = 2.3, three = 3.9)
cbind(as.matrix(a), as.matrix(b))
xgb_grid_1
cut(xgb_grid_1$nrounds)
cut(xgb_grid_1$nrounds, 4)
cut(xgb_grid_1$eta, 4)
?cut
##----------------------------------------------------------------------------------
## GET PREDICTIONS
##----------------------------------------------------------------------------------
source("~/Desktop/photo_kaggle/setting_wd.R") #set working directory.
source("./src/dt_preprocessing.R")
library(data.table); library(xgboost); library(caret); library(pROC); library(ROCR); library(ggplot2)
set.seed(123)
##----------------------------------------------------------------------------------
## Training data preprocessing, appending/modifying features.
##----------------------------------------------------------------------------------
assemble_data <- function(train_or_test = "train",
data_file = "./data/training.csv",
name_tfidf_file = "./data/train_name_tfidf.rds",
desc_caption_tfidf_file = "./data/train_desc_caption_tfidf.rds",
country_file = "./data/aggregate_train_countries.RDS"){
dt <- fread(data_file)
dt <- remove_columns(add_area(dt))
if(train_or_test == "train"){
print("Assembling training data...")
y <- as.matrix(as.numeric(dt[["good"]]))
dt[, "good":=NULL]
} else print("Assembling test data for predictions...")
name_tfidf <- readRDS(name_tfidf_file); desc_caption_tfidf <- readRDS(desc_caption_tfidf_file)
country <- data.frame("country" = readRDS(country_file))
#If assembling test data, impute the most common country if country name is missing.
if(train_or_test == "test"){
country$country[which(is.na(country))] <- names(which.max(table(country)))
} else{
rm_inds <- which(is.na(country))
}
country_one_hot <- model.matrix(~0+country, data = country)
df_text <- cbind(dt, name_tfidf) #names text data
df_text <- cbind(df_text, desc_caption_tfidf) #description/caption text data
colnames(df_text) <- make.names(colnames(df_text), unique = T)
if(train_or_test == "train"){
df_text <- df_text[-rm_inds, ]
y <- y[-rm_inds]
return(list(data = as.matrix(cbind(df_text, country_one_hot)), y = y))
} else{
return(list(data = as.matrix(cbind(df_text, country_one_hot))))
}
}
train_data <- assemble_data()
train <- train_data$data; y <- train_data$y
##----------------------------------------------------------------------------------
## For an example, fit one xgboost model with random parameters.
##----------------------------------------------------------------------------------
#split data into training/test sets:
trainIndex <- as.vector(caret::createDataPartition(y = y,
p = 0.8,
list = FALSE))
#store explicitly the training data
train.DMat <- xgb.DMatrix(data = train[trainIndex, ], label = y[trainIndex])
#store explicitly the validation data
valid.DMat <- xgb.DMatrix(data = train[-trainIndex, ], label = y[-trainIndex])
#hyperparameters
max.depth <- 8 #How deep each weak learner (small tree) can get. Will control overfitting.
eta <- 0.5 #eta is the learning rate, which also has to do with regularization. 1 ->> no regularization. 0 < eta <= 1.
nround <- 150 #The number of passes over training data. This is the number of trees we're ensembling.
#Fit boosted model with our random parameters. Save output that would otherwise print to console.
sink("./data/watchlist_output.txt", append = FALSE)
bst <- xgb.train(data = train.DMat,
watchlist = list(train = train.DMat, validation = valid.DMat),
max.depth = max.depth,
eta = eta, nthread = 4,
nround = nround,
objective = "binary:logistic",
eval_metric = "logloss")
sink()
#View training/validation logloss metrics:
bst_output <- read.table("./data/watchlist_output.txt", sep = "\t")
# which.min(sapply(bst_output[,3], FUN = function(x){as.numeric(substr(x, 14, 21))}))
valid.preds <- predict(bst, valid.DMat) #Xgboost::predict returns class probabilities, not class labels!
theta <- 0.5
valid.class_preds <- ifelse(valid.preds >= theta, 1, 0)
valid.accuracy <- sum(as.numeric(valid.class_preds == y[-trainIndex]))/length(y[-trainIndex]) #~78% valid accuracy
print(sprintf("Accuracy on validation set: %f", valid.accuracy))
##----------------------------------------------------------------------------------
## Tune xgb model with a gridsearch over parameters and cross validation.
##----------------------------------------------------------------------------------
#Define hyperparameter grid. This one will call for 8 models.
#Note, the parameter names in caret are different than in xgb.train.
xgb_grid <- expand.grid(nrounds = c(100),
eta = c(0.2),
max_depth = c(7, 10),
colsample_bytree = c(0.6, 1),
gamma = c(0.75, 1),
min_child_weight = c(1))
tr_control <- caret::trainControl(method = "cv",
number = 5,
classProbs = TRUE,
allowParallel = TRUE,
summaryFunction = mnLogLoss, #Use summaryFunction will use ROC (i.e. AUC) to select optimal model. Write custom one.
verboseIter = TRUE)
xgb_cv1 <- caret::train(x = train,
y = as.factor(ifelse(y==1, "good", "bad")), #target vector should be non-numeric factors
tuneGrid = xgb_grid, #Which hyperparameters we'll test.
trControl = tr_control, #How cross validation will run.
method = "xgbTree",
metric = "logLoss",
maximize = FALSE)
importance_matrix <- xgb.importance(model = bst, names = colnames(train))
?xgb.importance
importance_matrix <- xgb.importance(model = bst, feature_names = colnames(train))
barplot(importance_matrix$Gain[10:1], horiz = T, names.arg = importance_matrix$Feature[10:1],
main = "Estimated top 10 features by predictive power gain")
barplot(importance_matrix$Gain[10:1],
horiz = T,
names.arg = importance_matrix$Feature[10:1],
main = "Estimated top 10 features by predictive power gain",
cex.lab = .75)
barplot(importance_matrix$Gain[10:1],
horiz = T,
names.arg = importance_matrix$Feature[10:1],
main = "Estimated top 10 features by predictive power gain",
cex.lab = .1)
barplot(importance_matrix$Gain[10:1],
horiz = T,
names.arg = importance_matrix$Feature[10:1],
main = "Estimated top 10 features by predictive power gain",
las = 1)
barplot(importance_matrix$Gain[10:1],
horiz = T,
names.arg = importance_matrix$Feature[10:1],
main = "Estimated top 10 features by predictive power gain",
las = 1,
cex.lab = .4)
par(mar=c(8,8,1,1))
barplot(importance_matrix$Gain[10:1],
horiz = T,
names.arg = importance_matrix$Feature[10:1],
main = "Estimated top 10 features by predictive power gain",
las = 1,
cex.lab = .4)
dev.off()
barplot(importance_matrix$Gain[10:1],
horiz = T,
names.arg = importance_matrix$Feature[10:1],
main = "Estimated top 10 features by predictive power gain",
las = 1,
cex.names = .5)
barplot(importance_matrix$Gain[10:1],
horiz = T,
names.arg = importance_matrix$Feature[10:1],
main = "Estimated top 10 features by predictive power gain",
cex.names = .5)
barplot(importance_matrix$Gain[6:1],
horiz = T,
names.arg = importance_matrix$Feature[6:1],
main = "Estimated top 6 features by predictive power gain",
cex.names = .6)
barplot(importance_matrix$Gain[6:1],
horiz = T,
names.arg = importance_matrix$Feature[6:1],
main = "Estimated top 6 features by predictive power gain",
cex.names = .6)
barplot(importance_matrix$Gain[6:1],
horiz = T,
names.arg = importance_matrix$Feature[6:1],
main = "Estimated top 6 features by predictive power gain",
cex.names = .6)
barplot(importance_matrix$Gain[6:1],
horiz = T,
names.arg = importance_matrix$Feature[6:1],
main = "Estimated top 6 features by accuracy improvement gain",
cex.names = .6)
barplot(importance_matrix$Gain[6:1],
horiz = T,
names.arg = importance_matrix$Feature[6:1],
main = "Estimated top 6 features by accuracy gain",
cex.names = .6)
?ggsave
setwd("~/Desktop/FrankFineis.github.io/rmd.path/")
site.path <- site.path
site.path='~/Desktop/FrankFineis.github.io/'
rmd.path <- paste0(site.path, "_Rmd")
rmd.path
site.path <- site.path # directory of jekyll blog (including trailing slash)
rmd.path <- paste0(site.path, "_Rmd") # directory where your Rmd-files reside (relative to base)
fig.dir <- paste0(site.path, "images")# directory to save figures
posts.path <- paste0(site.path, "blog/_posts") # directory for converted markdown files
cache.path <- paste0(site.path, "_cache") # necessary for plots
KnitPost <- function(site.path='~/Desktop/FrankFineis.github.io/', overwriteAll=F, overwriteOne=NULL) {
if(!'package:knitr' %in% search()) library('knitr')
## Blog-specific directories.  This will depend on how you organize your blog.
site.path <- site.path # directory of jekyll blog (including trailing slash)
rmd.path <- paste0(site.path, "_Rmd") # directory where your Rmd-files reside (relative to base)
fig.dir <- paste0(site.path, "images")# directory to save figures
posts.path <- paste0(site.path, "blog/_posts") # directory for converted markdown files
cache.path <- paste0(site.path, "_cache") # necessary for plots
render_jekyll(highlight = "pygments")
opts_knit$set(base.url = '/', base.dir = site.path)
opts_chunk$set(fig.path=fig.dir, fig.width=8.5, fig.height=5.25, dev='svg', cache=F,
warning=F, message=F, cache.path=cache.path, tidy=F)
setwd(rmd.path) # setwd to base
# some logic to help us avoid overwriting already existing md files
files.rmd <- data.frame(rmd = list.files(path = rmd.path,
full.names = T,
pattern = "\\.Rmd$",
ignore.case = T,
recursive = F), stringsAsFactors=F)
files.rmd$corresponding.md.file <- paste0(posts.path, "/", basename(gsub(pattern = "\\.Rmd$", replacement = ".md", x = files.rmd$rmd)))
files.rmd$corresponding.md.exists <- file.exists(files.rmd$corresponding.md.file)
## determining which posts to overwrite from parameters overwriteOne & overwriteAll
files.rmd$md.overwriteAll <- overwriteAll
if(is.null(overwriteOne)==F) files.rmd$md.overwriteAll[grep(overwriteOne, files.rmd[,'rmd'], ignore.case=T)] <- T
files.rmd$md.render <- F
for (i in 1:dim(files.rmd)[1]) {
if (files.rmd$corresponding.md.exists[i] == F) {
files.rmd$md.render[i] <- T
}
if ((files.rmd$corresponding.md.exists[i] == T) && (files.rmd$md.overwriteAll[i] == T)) {
files.rmd$md.render[i] <- T
}
}
# For each Rmd file, render markdown (contingent on the flags set above)
for (i in 1:dim(files.rmd)[1]) {
if (files.rmd$md.render[i] == T) {
out.file <- knit(as.character(files.rmd$rmd[i]),
output = as.character(files.rmd$corresponding.md.file[i]),
envir = parent.frame(),
quiet = T)
message(paste0("KnitPost(): ", basename(files.rmd$rmd[i])))
}
}
}
KnitPost()
KnitPost <- function(site.path='~/Desktop/FrankFineis.github.io/', overwriteAll=F, overwriteOne=NULL) {
if(!'package:knitr' %in% search()) library('knitr')
## Blog-specific directories.  This will depend on how you organize your blog.
site.path <- site.path # directory of jekyll blog (including trailing slash)
rmd.path <- paste0(site.path, "_Rmd") # directory where your Rmd-files reside (relative to base)
fig.dir <- paste0(site.path, "images")# directory to save figures
posts.path <- paste0(site.path, "blog/_posts") # directory for converted markdown files
cache.path <- paste0(site.path, "_cache") # necessary for plots
render_jekyll(highlight = "pygments")
opts_knit$set(base.url = '/', base.dir = site.path)
opts_chunk$set(fig.path=fig.dir, fig.width=8.5, fig.height=5.25, dev='svg', cache=F,
warning=F, message=F, cache.path=cache.path, tidy=F)
setwd(rmd.path) # setwd to base
# some logic to help us avoid overwriting already existing md files
files.rmd <- data.frame(rmd = list.files(path = rmd.path,
full.names = T,
pattern = "\\.Rmd$",
ignore.case = T,
recursive = F), stringsAsFactors=F)
files.rmd$corresponding.md.file <- paste0(posts.path, "/", basename(gsub(pattern = "\\.Rmd$", replacement = ".md", x = files.rmd$rmd)))
files.rmd$corresponding.md.exists <- file.exists(files.rmd$corresponding.md.file)
## determining which posts to overwrite from parameters overwriteOne & overwriteAll
files.rmd$md.overwriteAll <- overwriteAll
if(is.null(overwriteOne)==F) files.rmd$md.overwriteAll[grep(overwriteOne, files.rmd[,'rmd'], ignore.case=T)] <- T
files.rmd$md.render <- F
for (i in 1:dim(files.rmd)[1]) {
if (files.rmd$corresponding.md.exists[i] == F) {
files.rmd$md.render[i] <- T
}
if ((files.rmd$corresponding.md.exists[i] == T) && (files.rmd$md.overwriteAll[i] == T)) {
files.rmd$md.render[i] <- T
}
}
# For each Rmd file, render markdown (contingent on the flags set above)
for (i in 1:dim(files.rmd)[1]) {
if (files.rmd$md.render[i] == T) {
out.file <- knit(as.character(files.rmd$rmd[i]),
output = as.character(files.rmd$corresponding.md.file[i]),
envir = parent.frame(),
quiet = T)
message(paste0("KnitPost(): ", basename(files.rmd$rmd[i])))
}
}
}
KnitPost()
KnitPost()
KnitPost()
KnitPost()
KnitPost()
KnitPost()
KnitPost()
KnitPost()
KnitPost <- function(site.path='~/Desktop/FrankFineis.github.io/', overwriteAll=F, overwriteOne=NULL) {
if(!'package:knitr' %in% search()) library('knitr')
## Blog-specific directories.  This will depend on how you organize your blog.
site.path <- site.path # directory of jekyll blog (including trailing slash)
rmd.path <- paste0(site.path, "_Rmd") # directory where your Rmd-files reside (relative to base)
fig.dir <- paste0(site.path, "images")# directory to save figures
posts.path <- paste0(site.path, "blog/_posts") # directory for converted markdown files
cache.path <- paste0(site.path, "_cache") # necessary for plots
render_jekyll(highlight = "pygments")
opts_knit$set(base.url = '/', base.dir = site.path)
opts_chunk$set(fig.path=fig.dir, fig.width=8.5, fig.height=5.25, dev='svg', cache=F,
warning=F, message=F, cache.path=cache.path, tidy=F)
setwd(rmd.path) # setwd to base
# some logic to help us avoid overwriting already existing md files
files.rmd <- data.frame(rmd = list.files(path = rmd.path,
full.names = T,
pattern = "\\.Rmd$",
ignore.case = T,
recursive = F), stringsAsFactors=F)
files.rmd$corresponding.md.file <- paste0(posts.path, "/", basename(gsub(pattern = "\\.Rmd$", replacement = ".md", x = files.rmd$rmd)))
files.rmd$corresponding.md.exists <- file.exists(files.rmd$corresponding.md.file)
## determining which posts to overwrite from parameters overwriteOne & overwriteAll
files.rmd$md.overwriteAll <- overwriteAll
if(is.null(overwriteOne)==F) files.rmd$md.overwriteAll[grep(overwriteOne, files.rmd[,'rmd'], ignore.case=T)] <- T
files.rmd$md.render <- F
for (i in 1:dim(files.rmd)[1]) {
if (files.rmd$corresponding.md.exists[i] == F) {
files.rmd$md.render[i] <- T
}
if ((files.rmd$corresponding.md.exists[i] == T) && (files.rmd$md.overwriteAll[i] == T)) {
files.rmd$md.render[i] <- T
}
}
# For each Rmd file, render markdown (contingent on the flags set above)
for (i in 1:dim(files.rmd)[1]) {
if (files.rmd$md.render[i] == T) {
out.file <- knit(as.character(files.rmd$rmd[i]),
output = as.character(files.rmd$corresponding.md.file[i]),
envir = parent.frame(),
quiet = T)
message(paste0("KnitPost(): ", basename(files.rmd$rmd[i])))
}
}
}
KnitPost()
KnitPost()
KnitPost()
KnitPost()
KnitPost()
